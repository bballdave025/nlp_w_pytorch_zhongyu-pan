{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Course For NLP from LinkedIn\n",
        "\n",
        "Heavenly Father is guiding me - this one has a text classification project.\n",
        "\n",
        "https://www.linkedin.com/learning/natural-language-processing-with-pytorch/popular-topics-in-nlp\n",
        "\n",
        "The teacher is Zhonyu Pan, Content Creator at LinkedIn\n",
        "\n",
        "We'll be using PyTorch, and we'll use a Convolutional Neural Network (feature rather than position) to do our text classification.\n",
        "\n",
        "`Input -> Convolution -> Pooling -> ... -> Fully-connected layer -> Output`"
      ],
      "metadata": {
        "id": "W48See-I_f_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are also learning about RNNs. RNN doesn't only pass data forward, but only feeds the data back into itself. CNN only goes forward. RNN can remember context before and after words in a sequence. It's usually slower that a CNN."
      ],
      "metadata": {
        "id": "GqEnKH80AaBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to learn PyTorch"
      ],
      "metadata": {
        "id": "-6_fGW1HAqF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>PyTorch tensor</b>\n",
        "\n",
        "A tensor is a data structure or data container we use in PyTorch for carrying arrays of numbers.\n",
        "\n",
        "<b>a. Creating a tensor</b>"
      ],
      "metadata": {
        "id": "RpRO_Uu4BRg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: use pip to install PyTorch\n",
        "\n",
        "#!pip install torch torchvision\n",
        "!pip install torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aylFvJ8JBMAO",
        "outputId": "f77deace-2573-451c-d40c-91348b6f282d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import pytorch as well as numpy\n",
        "\n",
        "import torch\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "xG4ROa2_Bkn_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  prompt: Construct a tensor named tensor0 from the array,\n",
        "#+ array = [[1, 2], [7, 4],[5, 6]].\n",
        "#+ Print the tensor.\n",
        "#+ Output \"The data structure type of tensor0: \",\n",
        "#+ then appropriately continue the statement using code.\n",
        "#+ After, output \"The data type of tensor0: \" and continue\n",
        "#+ the statement appropriately using code.\n",
        "\n",
        "#import torch\n",
        "\n",
        "# Create a tensor named tensor0 from the array\n",
        "array = [[1, 2], [7, 4], [5, 6]]\n",
        "tensor0 = torch.tensor(array)\n",
        "\n",
        "## Added by DWB\n",
        "print(tensor0)\n",
        "\n",
        "# Print the tensor\n",
        "print(\"The data structure type of tensor0: \", type(tensor0))\n",
        "\n",
        "# Print the data type of tensor0\n",
        "print(\"The data type of tensor0: \", tensor0.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ohR_UzloB1V-",
        "outputId": "3cdc9c30-2b7e-4cac-feb2-422b61bd4c3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [7, 4],\n",
            "        [5, 6]])\n",
            "The data structure type of tensor0:  <class 'torch.Tensor'>\n",
            "The data type of tensor0:  torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  prompt: Now, create a tensor named tensor0 from the same data,\n",
        "#+ but as a numpy array. Continue the other steps as before.\n",
        "\n",
        "#import torch\n",
        "#import numpy as np\n",
        "\n",
        "# Create a tensor named tensor0 from the array as a numpy array\n",
        "array = np.array([[1, 2], [7, 4], [5, 6]])\n",
        "tensor1 = torch.tensor(array)\n",
        "\n",
        "## Added by DWB\n",
        "print(tensor1)\n",
        "\n",
        "# Print the tensor\n",
        "print(\"The data structure type of tensor1: \", type(tensor1))\n",
        "\n",
        "# Print the data type of tensor1\n",
        "print(\"The data type of tensor1: \", tensor1.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FK8foyVXC_qz",
        "outputId": "1b27a79d-f680-4147-860e-0f9ef04ad527"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [7, 4],\n",
            "        [5, 6]])\n",
            "The data structure type of tensor1:  <class 'torch.Tensor'>\n",
            "The data type of tensor1:  torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>b. Common Methods: Slicing and Concatenation</b>"
      ],
      "metadata": {
        "id": "BGV5nNg5EMqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Slicing_"
      ],
      "metadata": {
        "id": "vsciqjObEZ7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create tensorA = tensor([[1.,1.,1.],[2.,2.,2.]])\n",
        "# so that the two rows of tensorA are different.\n",
        "# and... create tensorB = tensor([[3.,3.,3.],[4.,4.,4.]])\n",
        "# so that the two rows of tensorB are different\n",
        "# using only PyTorch methods.\n",
        "# Print the contents of the two tensors.\n",
        "\n",
        "#import torch\n",
        "\n",
        "# Create tensorA with two different rows\n",
        "tensorA = torch.cat((torch.ones(1, 3), 2 * torch.ones(1, 3)), dim=0)\n",
        "\n",
        "# Create tensorB with two different rows\n",
        "tensorB = torch.cat((3 * torch.ones(1, 3), 4 * torch.ones(1, 3)), dim=0)\n",
        "\n",
        "# Print the contents of the two tensors\n",
        "print(\"tensorA:\", tensorA)\n",
        "print(\"tensorB:\", tensorB)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "evZyM4YgDWM7",
        "outputId": "3db45d33-c3a8-4ad6-a390-ee4547402518"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorA: tensor([[1., 1., 1.],\n",
            "        [2., 2., 2.]])\n",
            "tensorB: tensor([[3., 3., 3.],\n",
            "        [4., 4., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Impressive, but you can pass in '[[1.,1.,1.],[2.,2.,2.]]' for tensorA\n",
        "# and '[[3.,3.,3.],[4.,4.,4.]]' for tensorB.\n",
        "\n",
        "## Create tensorA with two different rows\n",
        "#tensorA = torch.cat((torch.ones(1, 3), 2 * torch.ones(1, 3)), dim=0)\n",
        "#\n",
        "## Create tensorB with two different rows\n",
        "#tensorB = torch.cat((3 * torch.ones(1, 3), 4 * torch.ones(1, 3)), dim=0)\n",
        "#\n",
        "## Print the contents of the two tensors\n",
        "#print(\"tensorA:\", tensorA)\n",
        "#print(\"tensorB:\", tensorB)\n",
        "\n",
        "# Pass in '[[1.,1.,1.],[2.,2.,2.]]' for tensorA\n",
        "# and '[[3.,3.,3.],[4.,4.,4.]]' for tensorB\n",
        "tensorA = torch.tensor([[1.,1.,1.],[2.,2.,2.]])\n",
        "tensorB = torch.tensor([[3.,3.,3.],[4.,4.,4.]])\n",
        "\n",
        "# Print the contents of the two tensors\n",
        "print(\"tensorA:\", tensorA)\n",
        "print(\"tensorB:\", tensorB)\n"
      ],
      "metadata": {
        "id": "Fw9f1NZfE_af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Output\n",
        "# \"Slicing the first two rows of tensorA\" + \\\n",
        "# \"(index one inclusive, index two exclusive)\",\n",
        "# then write the code to do so and print the result\n",
        "# Follow the same procedure with the text,\n",
        "# \"Slicing the first two columns of tensorA\" + \\\n",
        "# \"(take all rows, then slice columns)\".\n",
        "\n",
        "# Slicing the first two rows of tensorA (index one inclusive, index two exclusive)\n",
        "print(\"Slicing the first two rows of tensorA (index one inclusive, index two exclusive):\")\n",
        "print(tensorA[1:2, :])\n",
        "\n",
        "# Slicing the first two columns of tensorA (take all rows, then slice columns)\n",
        "print(\"Slicing the first two columns of tensorA (take all rows, then slice columns):\")\n",
        "print(tensorA[:, :2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KFKLxk46J7JC",
        "outputId": "6d268d19-ef66-4052-d0a3-60398867dce2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slicing the first two rows of tensorA (index one inclusive index two exclusive):\n",
            "tensor([[1., 1., 1.],\n",
            "        [2., 2., 2.]])\n",
            "Slicing the first two columns of tensorA (take all rows, then slice columns):\n",
            "tensor([[1., 1.],\n",
            "        [2., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her code"
      ],
      "metadata": {
        "id": "BUYTzF8SMHKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Slicing is all the same as numpy arrays\n",
        "print('Slicing the first two rows of tensorA (index one inclusive index two exclusive): ')\n",
        "print(tensorA[:2])\n",
        "print(\"Slicing the first two columns of tensorA (take all rows, then slice columns):\")\n",
        "print(tensorA[:, :2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UPjuJlPSKEO8",
        "outputId": "30811942-b8a9-44d1-cb01-b08547dc6680"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slicing the first two rows of tensorA (index one inclusive index two exclusive): \n",
            "tensor([[1., 1., 1.],\n",
            "        [2., 2., 2.]])\n",
            "Slicing the first two columns of tensorA (take all rows, then slice columns):\n",
            "tensor([[1., 1.],\n",
            "        [2., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Concatenation_"
      ],
      "metadata": {
        "id": "FIhVB9MPM2cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Output\n",
        "# \"Vertically concatenate tensorA and tensorB: (default: dim=0)\"\n",
        "# then do so, using the variable concat_v. Then, print the variable.\n",
        "\n",
        "## It did too much again : )\n",
        "#import torch\n",
        "#\n",
        "## Create tensorA with two different rows\n",
        "#tensorA = torch.tensor([[1.,1.,1.],[2.,2.,2.]])\n",
        "#tensorB = torch.tensor([[3.,3.,3.],[4.,4.,4.]])\n",
        "#\n",
        "## Print the contents of the two tensors\n",
        "#print(\"tensorA:\", tensorA)\n",
        "#print(\"tensorB:\", tensorB)\n",
        "\n",
        "# Vertically concatenate tensorA and tensorB: (default: dim=0)\n",
        "concat_v = torch.cat((tensorA, tensorB), dim=0)\n",
        "print(\"Vertically concatenate tensorA and tensorB: (default: dim=0)\")\n",
        "print(concat_v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YPwlEbI0MuD3",
        "outputId": "aa59f372-ffd9-4159-c239-f4b023e4777e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vertically concatenate tensorA and tensorB: (default: dim=0)\n",
            "tensor([[1., 1., 1.],\n",
            "        [2., 2., 2.],\n",
            "        [3., 3., 3.],\n",
            "        [4., 4., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Follow the same procedure as before, but with the text,\n",
        "# \"Horizontally concatenate tensorA and tensorB (dim=1)\"\n",
        "# and the variable, concat_h\n",
        "\n",
        "# Horizontally concatenate tensorA and tensorB (dim=1)\n",
        "concat_h = torch.cat((tensorA, tensorB), dim=1)\n",
        "print(\"Horizontally concatenate tensorA and tensorB (dim=1)\")\n",
        "print(concat_h)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SoTDqSAENZMW",
        "outputId": "be0ad55b-910e-4dfe-e18c-fe0228aae69f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Horizontally concatenate tensorA and tensorB (dim=1)\n",
            "tensor([[1., 1., 1., 3., 3., 3.],\n",
            "        [2., 2., 2., 4., 4., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her code was a bit different."
      ],
      "metadata": {
        "id": "oY_Xv-FmN5WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "concat_v = torch.cat([tensorA, tensorB])\n",
        "concat_h = torch.cat([tensorA, tensorB], dim=1)\n",
        "\n",
        "print(concat_v)\n",
        "print(concat_h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "i49i6zGVN75d",
        "outputId": "30537d6a-3c1d-4837-d856-8e16f484564e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [2., 2., 2.],\n",
            "        [3., 3., 3.],\n",
            "        [4., 4., 4.]])\n",
            "tensor([[1., 1., 1., 3., 3., 3.],\n",
            "        [2., 2., 2., 4., 4., 4.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CoPilot generation was fun. I got to learn prompt engineering, especially with the original 2x3 tensors. It did it with only PyTorch methods, but I had to be pretty explicit. Then, I told it that it could pass in arrays."
      ],
      "metadata": {
        "id": "wsYAwtEXOne0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!date +'%s_%Y-%m-%dT%H:%M:%S%z'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "grquJF_9O3tT",
        "outputId": "695b7060-bab7-4a04-a6a7-ee4bbf0c42ce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1718947145_2024-06-21T05:19:05+0000\n"
          ]
        }
      ]
    }
  ]
}