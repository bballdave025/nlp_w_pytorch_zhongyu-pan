{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bballdave025/nlp_w_pytorch_zhongyu-pan/blob/main/PyTorch_CNN_Text___LinkedIn_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network for Text Classification Using PyTorch"
      ],
      "metadata": {
        "id": "55KVBFK78Iag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Go straight to the code](#Installs_and_Imports)"
      ],
      "metadata": {
        "id": "WaIL7xmHVEuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Navigation - Get the Notebook from Different Places for Different Uses\n",
        "\n",
        "### (Navigation for the main presentation notebook)\n",
        "\n",
        "[Google CoLab on my Google Drive](https://colab.research.google.com/drive/1PKkdbNcqUfV0sHCosWZf3JdF6F3kGoj7?usp=sharing) - A place to see all inputs\n",
        "and outputs for the notebook, though you can't edit it without re-saving it.\n",
        "\n",
        "<br/>\n",
        "\n",
        "[GitHub Repo (link to be put in, soon)](#) - Code repository: a place to see the latest changes as well as the Jupyter Notebooks completed earlier\n",
        "\n",
        "<br/>\n",
        "\n",
        "[GitHub Notebook File (link to be put in, soon)](#) - I don't think this\n",
        "is as useful as the repo, but you can see the IPYNB file placeholder.\n",
        "This file will only have input - I scrub the output before committing\n",
        "any updates, because it's easier to do `diff`s (see changes in code)\n",
        "on Jupyter Notebooks when you don't have the outputs.\n",
        "\n",
        "<br/>\n",
        "\n",
        "[On MyBinder (link to be put in, soon)](#) - A place to interact with the notebook, where you'll be led to the notebook without output and can\n",
        "run the code and see the results yourself.<br/>\n",
        "A note, [MyBinder](https://mybinder.org) is a great online project which allows you to interactively run a Jupyter notebook completely online. It's nice to have when you'd like to play with code and better see the outputs that come from running that code. I've had some problems with images going down, but I'm going to work to keep this one up and running for access."
      ],
      "metadata": {
        "id": "HU93StT09nAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting Together All the Work from the Course"
      ],
      "metadata": {
        "id": "jVzAxwDI7vJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Course For NLP from LinkedIn\n",
        "\n",
        "https://www.linkedin.com/learning/natural-language-processing-with-pytorch\n",
        "\n",
        "The teacher is Zhonyu Pan, Content Creator at LinkedIn\n",
        "\n",
        "We use PyTorch and a Convolutional Neural Network (using NLP features\n",
        "rather than the pixel position features we use with image processing) to\n",
        "do our text classification.\n",
        "\n",
        "`Input -> Convolution -> Pooling -> ... -> Fully-connected layer -> Output`"
      ],
      "metadata": {
        "id": "yzW07eEC9VzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are also learning about RNNs. RNN doesn't only pass data forward, but also feeds the data back into itself. CNN only goes forward. RNN can remember context before and after words in a sequence. It's usually slower that a CNN."
      ],
      "metadata": {
        "id": "GMXpg60q9jcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installs and Imports"
      ],
      "metadata": {
        "id": "Dl1dzqUi8R4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Robust Install-if-Needed Code\n",
        "\n",
        "(I don't want to have to mess with whether the runtime has been\n",
        "disconnected or if the version is right or whatever.)"
      ],
      "metadata": {
        "id": "zHGQJEZz8_v4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Functions</b>\n",
        "\n",
        "@todo: These should be put in a class and added to my `python_util`\n",
        "  repo in GitHub. Actually, no. I will put the stuff I've learned in a gist\n",
        "  or something, but no one should use this unless you know exactly what I\n",
        "  mean when I say \"typo-enabled-package-injection\" as it relates to PyPI.\n",
        "\n",
        "I'm just going to make something simple that makes sure I install the\n",
        "packages I need if they haven't already been installed. This will be\n",
        "especially useful for CoLab.\n",
        "\n",
        "<b> DON'T USE THIS FUNCTIONIONALITY (outside of this notebook)\n",
        "    UNLESS YOU UNDERSTAND THE IDEA/MEANING OF THE WORDS THAT FOLLOW -\n",
        "    \"typo-squatting-attack\"\n",
        "    \"typo-enabled-package-injection\" - AND UNLESS YOU UNDERSTAND THE\n",
        "    IMPLICATIONS AND RISKS AS THEY (THE WORDS AND THE CONCEPT) RELATE\n",
        "    TO PyPI AND TO `pip` INSTALLS!</b>"
      ],
      "metadata": {
        "id": "HQ3BoL6DJPX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib_metadata\n",
        "\n",
        "def is_package_installed(package_name):\n",
        "    try:\n",
        "        # <find-the-package-in-the-list>\n",
        "        dist = importlib_metadata.distribution(package_name)\n",
        "        print(f\"{package_name} {dist.version} is installed.\")\n",
        "        return True\n",
        "    except importlib_metadata.PackageNotFoundError:\n",
        "        print(f\"{package_name} is not installed.\")\n",
        "        return False\n",
        "    finally:\n",
        "        pass\n",
        "    ##endof:  try/except/finally <find-the-package-in-the-list>\n",
        "##endof:  def check_package_installed(package_name)"
      ],
      "metadata": {
        "id": "zVlbJxoK9JaS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### REMEMBER\n",
        "\n",
        "<b> DON'T USE THIS FUNCTIONIONALITY (outside of this notebook)\n",
        "    UNLESS YOU UNDERSTAND THE IDEA/MEANING OF THE WORDS THAT FOLLOW -\n",
        "    \"typo-squatting-attack\"\n",
        "    \"typo-enabled-package-injection\" - AND UNLESS YOU UNDERSTAND THE\n",
        "    IMPLICATIONS AND RISKS AS THEY (THE WORDS AND THE CONCEPT) RELATE\n",
        "    TO PyPI AND TO `pip` INSTALLS!</b>\n",
        "\n",
        "If that hasn't put [the fear of](https://books.google.com/ngrams/graph?content=the+fear+of+*+into&year_start=1800&year_end=2022&corpus=en&smoothing=3) Gerard into you, <strike>watch 300</strike>,\n",
        "look up \"python request typosquatting\" - there have been several attacks\n",
        "with just that (`requests`) package.\n",
        "\n",
        "### Install PyTorch and NumPy"
      ],
      "metadata": {
        "id": "KR-i0k4SVw8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib_metadata, importlib\n",
        "\n",
        "#-----------\n",
        "# PyTorch\n",
        "\n",
        "print(\"-\"*50)\n",
        "\n",
        "if not is_package_installed('torch'):\n",
        "    print(\"Installing 'torch'\")\n",
        "    !pip install torch\n",
        "##endof:  if not is_package_installed('torch')\n",
        "\n",
        "print(\"\\nLet's see the result of what we did for PyTorch.\")\n",
        "try:\n",
        "    dist = importlib_metadata.distribution('torch')\n",
        "    print(f\"torch {dist.version} is installed.\")\n",
        "except importlib_metadata.PackageNotFoundError:\n",
        "    print(f\"'torch' has not been installed.\")\n",
        "finally:\n",
        "    pass\n",
        "##endof:  try/except/finally\n",
        "\n",
        "#-----------------------\n",
        "# PyTorch Text (Legacy)\n",
        "\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "if not is_package_installed('torchtext'):\n",
        "    print(\"Installing 'torchtext'\")\n",
        "    !pip install torchtext\n",
        "##endof:  if not is_package_installed('torchtext')\n",
        "\n",
        "print(\"\\nLet's see the result of what we did for PyTorch Text.\")\n",
        "try:\n",
        "    dist = importlib_metadata.distribution('torchtext')\n",
        "    print(f\"torchtext {dist.version} is installed.\")\n",
        "except importlib_metadata.PackageNotFoundError:\n",
        "    print(f\"'torchtext' has not been installed.\")\n",
        "finally:\n",
        "    pass\n",
        "##endof:  try/except/finally\n",
        "\n",
        "print(\"\\n\\n\" + \"-\"*60)\n",
        "\n",
        "#----------------------------------------\n",
        "#  NumPy (version less than 2)\n",
        "#+ I pulled from the course's GitHub\n",
        "#+ repo before numpy 2.0.0 was released.\n",
        "\n",
        "do_debug_numpy = True\n",
        "\n",
        "if is_package_installed('numpy'):\n",
        "    dist = importlib_metadata.distribution('numpy')\n",
        "    import numpy\n",
        "    np_version = numpy.__version__\n",
        "    if do_debug_numpy:\n",
        "      print(f\"numpy version: {np_version}\")\n",
        "    ##endof:  if do_debug_numpy\n",
        "    np_major_version = np_version.split('.')[0]\n",
        "    if do_debug_numpy:\n",
        "      print(f\"numpy major version: {np_major_version}\")\n",
        "    ##endof:  if do_debug_numpy\n",
        "    if int(np_major_version) >= 2:\n",
        "      ## if {the version is not <2}\n",
        "      if do_debug_numpy:\n",
        "        print(\"Inside the if {the version is not <2}\")\n",
        "      ##endof:  if do_debug_numpy\n",
        "      print(\"Uninstalling current (incorrect) version of numpy ...\")\n",
        "      !pip uninstall -y numpy\n",
        "      print(\"Installing 'numpy<2'\")\n",
        "      !pip install 'numpy<2'\n",
        "    else:\n",
        "      if do_debug_numpy:\n",
        "        print( (\"Inside the else for {the version is not <2}, \"\n",
        "                \"i.e. the version is < 2\")\n",
        "        )\n",
        "      ##endof:  if do_debug_numpy\n",
        "      print(f\"numpy version {numpy.__version__} is OK.\")\n",
        "    ##endof:  if/else {the-version-is-not-<2}\n",
        "else:\n",
        "    print(\"Installing 'numpy<2'\")\n",
        "    !pip install 'numpy<2'\n",
        "##endof:  if is_package_installed('numpy')\n",
        "\n",
        "print(\"\\nLet's see the result of what we did for NumPy.\")\n",
        "try:\n",
        "    dist = importlib_metadata.distribution('numpy')\n",
        "    print(f\"numpy {dist.version} is installed.\")\n",
        "except importlib_metadata.PackageNotFoundError:\n",
        "    print(f\"'numpy' has not been installed.\")\n",
        "finally:\n",
        "    pass\n",
        "##endof:  try/except/finally\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJh_9QM7WuKB",
        "outputId": "82dc2b30-1d3d-44bd-b4db-a1de3832ba27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "torch 2.4.0+cu121 is installed.\n",
            "\n",
            "Let's see the result of what we did for PyTorch.\n",
            "torch 2.4.0+cu121 is installed.\n",
            "\n",
            "--------------------------------------------------\n",
            "torchtext 0.18.0 is installed.\n",
            "\n",
            "Let's see the result of what we did for PyTorch Text.\n",
            "torchtext 0.18.0 is installed.\n",
            "\n",
            "\n",
            "------------------------------------------------------------\n",
            "numpy 2.1.1 is installed.\n",
            "numpy version: 2.1.1\n",
            "numpy major version: 2\n",
            "Inside the if {the version is not <2}\n",
            "Uninstalling current (incorrect) version of numpy ...\n",
            "Found existing installation: numpy 2.1.1\n",
            "Uninstalling numpy-2.1.1:\n",
            "  Successfully uninstalled numpy-2.1.1\n",
            "Installing numpy<2\n",
            "/bin/bash: line 1: 2: No such file or directory\n",
            "\n",
            "Let's see the result of what we did for NumPy.\n",
            "'numpy' was not installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the versions of PyTorch and NumPy that are given above.\n",
        "The extra stuff with the NumPy version is there because I\n",
        "pulled from the course's GitHub repo before `numpy 2.0.0`\n",
        "was released.\n",
        "\n",
        "These versions worked for this project as of ..."
      ],
      "metadata": {
        "id": "bWSRiPOWXLbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # I won't need this anymore\n",
        "#!date -u +\"%Y-%m-%dT%H%M%S%z\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0mfq5kKXSjQ",
        "outputId": "bc3f9cef-af82-42e0-c38c-b6680cce528a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-05T224706+0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output was\n",
        "\n",
        "`2024-09-05T224706+0000`\n",
        "\n",
        "... \\[versions that work ... as of ...\\] 2024-09-05 at 22:47:06 UTC+0000"
      ],
      "metadata": {
        "id": "QXBph8YvXwKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy import data, datasets\n",
        "import random"
      ],
      "metadata": {
        "id": "thiGiJugAuoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing text dataset**"
      ],
      "metadata": {
        "id": "QVCjmZdiwUzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 966\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "iOgPHnQtAutO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1bd2a1-bcb4-4f12-b055-f27162d5f23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(tokenize='spacy', lower=True)\n",
        "LABEL = data.LabelField()"
      ],
      "metadata": {
        "id": "dDVEivhqAuxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = datasets.TREC.splits(TEXT, LABEL)\n",
        "train, val = train.split(random_state = random.seed(seed))"
      ],
      "metadata": {
        "id": "BxiaBGivAu3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d901b255-6c14-47a7-d232-bfbcbe5fbea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading train_5500.label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 336k/336k [00:00<00:00, 3.04MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading TREC_10.label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23.4k/23.4k [00:00<00:00, 881kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vars(train[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxky-ODaRh0U",
        "outputId": "d5ac26d8-a58d-4060-8ff5-91275ecb6dc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'ENTY', 'text': ['how', 'do', 'you', 'say', '2', 'in', 'latin', '?']}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train, min_freq=2)\n",
        "LABEL.build_vocab(train)"
      ],
      "metadata": {
        "id": "JoM5PVpl5Kra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocabulary size of TEXT:\",len(TEXT.vocab.stoi))\n",
        "print(\"Vocabulary size of LABEL:\",len(LABEL.vocab.stoi))\n",
        "print(LABEL.vocab.stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKAd1xen2o5b",
        "outputId": "b6e86d3b-76be-48b5-d112-37e3e8efe007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size of TEXT: 2641\n",
            "Vocabulary size of LABEL: 6\n",
            "defaultdict(None, {'ENTY': 0, 'HUM': 1, 'DESC': 2, 'NUM': 3, 'LOC': 4, 'ABBR': 5})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train, val, test),\n",
        "    batch_size = 64,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "zEiW7Ri9S-el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building a Simple CNN Model**"
      ],
      "metadata": {
        "id": "hieTuqmvwieC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocabulary_size, embedding_size,\n",
        "               kernels_number, kernel_sizes, output_size, dropout_rate):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
        "    self.convolution_layers = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=kernels_number, kernel_size=(k, embedding_size))\n",
        "                                            for k in kernel_sizes])\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.fully_connected = nn.Linear(len(kernel_sizes) * kernels_number, output_size)\n",
        "  def forward(self, text):\n",
        "    text = text.permute(1, 0)\n",
        "    input_embeddings = self.embedding(text)\n",
        "    input_embeddings = input_embeddings.unsqueeze(1)\n",
        "    conved = [F.relu(convolution_layer(input_embeddings)).squeeze(3) for convolution_layer in self.convolution_layers]\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    concat = self.dropout(torch.cat(pooled, dim=1))\n",
        "    final_output = self.fully_connected(concat)\n",
        "    return final_output"
      ],
      "metadata": {
        "id": "sfXWPHz3S-hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(TEXT.vocab)\n",
        "embedding_size = 100\n",
        "kernels_number = 100\n",
        "kernel_sizes = [2, 3, 4]\n",
        "output_size = len(LABEL.vocab)\n",
        "dropout_rate = 0.3"
      ],
      "metadata": {
        "id": "pCURSmjUS-kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN(input_size, embedding_size, kernels_number, kernel_sizes, output_size, dropout_rate)"
      ],
      "metadata": {
        "id": "XOcYKu_SmQvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMjhG8IOmhZf",
        "outputId": "662a55ce-768f-4768-81ee-25caf8651911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (embedding): Embedding(2641, 100)\n",
            "  (convolution_layers): ModuleList(\n",
            "    (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fully_connected): Linear(in_features=300, out_features=6, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "aKcm7ZJQm9Oe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbda9754-d089-4a3b-d956-1092b570db94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embedding): Embedding(2641, 100)\n",
              "  (convolution_layers): ModuleList(\n",
              "    (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))\n",
              "    (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
              "    (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fully_connected): Linear(in_features=300, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and Evaluate Functions**"
      ],
      "metadata": {
        "id": "uMoLI86g0FA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "DUYzZfU9nBdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(predictions, actual_label):\n",
        "    max_predictions = predictions.argmax(dim = 1, keepdim = True, )\n",
        "    correct_predictions = max_predictions.squeeze(1).eq(actual_label)\n",
        "    accuracy = correct_predictions.sum() / torch.cuda.FloatTensor([actual_label.shape[0]])\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "Bk5boWJWnld4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(batch.text)\n",
        "\n",
        "        loss = criterion(predictions, batch.label)\n",
        "\n",
        "        acc = accuracy(predictions, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "ynHqY1ysoT57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "\n",
        "            acc = accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "XoIQYPOJo164"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "_CF2U8pZBq1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_epochs = 20\n",
        "\n",
        "best_acc = float('-inf')\n",
        "\n",
        "for epoch in range(number_of_epochs):\n",
        "\n",
        "    # Write the code here\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    # Write the code here\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    if valid_acc > best_acc:\n",
        "        # Write the code here\n",
        "        best_acc = valid_acc\n",
        "        torch.save(model.state_dict(), 'trec.pt')\n",
        "\n",
        "    print(f'Epoch {epoch+1} ')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Validation Loss: {valid_loss:.3f} |  Validation Acc: {valid_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "6Jd1eYGupW0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca13c6fe-59d4-41a6-a657-0e3323e7997b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            "\tTrain Loss: 1.312 | Train Acc: 48.76%\n",
            "\t Validation Loss: 0.952 |  Validation Acc: 64.50%\n",
            "Epoch 2 \n",
            "\tTrain Loss: 0.779 | Train Acc: 71.66%\n",
            "\t Validation Loss: 0.744 |  Validation Acc: 72.32%\n",
            "Epoch 3 \n",
            "\tTrain Loss: 0.585 | Train Acc: 81.01%\n",
            "\t Validation Loss: 0.654 |  Validation Acc: 74.99%\n",
            "Epoch 4 \n",
            "\tTrain Loss: 0.452 | Train Acc: 85.48%\n",
            "\t Validation Loss: 0.628 |  Validation Acc: 76.36%\n",
            "Epoch 5 \n",
            "\tTrain Loss: 0.359 | Train Acc: 88.29%\n",
            "\t Validation Loss: 0.583 |  Validation Acc: 78.56%\n",
            "Epoch 6 \n",
            "\tTrain Loss: 0.275 | Train Acc: 91.91%\n",
            "\t Validation Loss: 0.548 |  Validation Acc: 80.06%\n",
            "Epoch 7 \n",
            "\tTrain Loss: 0.207 | Train Acc: 94.12%\n",
            "\t Validation Loss: 0.550 |  Validation Acc: 80.89%\n",
            "Epoch 8 \n",
            "\tTrain Loss: 0.163 | Train Acc: 95.83%\n",
            "\t Validation Loss: 0.544 |  Validation Acc: 81.54%\n",
            "Epoch 9 \n",
            "\tTrain Loss: 0.137 | Train Acc: 96.33%\n",
            "\t Validation Loss: 0.530 |  Validation Acc: 81.62%\n",
            "Epoch 10 \n",
            "\tTrain Loss: 0.104 | Train Acc: 97.80%\n",
            "\t Validation Loss: 0.542 |  Validation Acc: 80.82%\n",
            "Epoch 11 \n",
            "\tTrain Loss: 0.090 | Train Acc: 98.02%\n",
            "\t Validation Loss: 0.546 |  Validation Acc: 81.08%\n",
            "Epoch 12 \n",
            "\tTrain Loss: 0.076 | Train Acc: 98.55%\n",
            "\t Validation Loss: 0.545 |  Validation Acc: 81.60%\n",
            "Epoch 13 \n",
            "\tTrain Loss: 0.066 | Train Acc: 98.47%\n",
            "\t Validation Loss: 0.548 |  Validation Acc: 81.96%\n",
            "Epoch 14 \n",
            "\tTrain Loss: 0.054 | Train Acc: 98.93%\n",
            "\t Validation Loss: 0.554 |  Validation Acc: 82.38%\n",
            "Epoch 15 \n",
            "\tTrain Loss: 0.048 | Train Acc: 99.09%\n",
            "\t Validation Loss: 0.557 |  Validation Acc: 81.67%\n",
            "Epoch 16 \n",
            "\tTrain Loss: 0.042 | Train Acc: 98.96%\n",
            "\t Validation Loss: 0.564 |  Validation Acc: 82.26%\n",
            "Epoch 17 \n",
            "\tTrain Loss: 0.038 | Train Acc: 99.28%\n",
            "\t Validation Loss: 0.562 |  Validation Acc: 82.45%\n",
            "Epoch 18 \n",
            "\tTrain Loss: 0.034 | Train Acc: 99.40%\n",
            "\t Validation Loss: 0.578 |  Validation Acc: 82.45%\n",
            "Epoch 19 \n",
            "\tTrain Loss: 0.030 | Train Acc: 99.38%\n",
            "\t Validation Loss: 0.599 |  Validation Acc: 82.44%\n",
            "Epoch 20 \n",
            "\tTrain Loss: 0.030 | Train Acc: 99.30%\n",
            "\t Validation Loss: 0.590 |  Validation Acc: 82.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('trec.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "mAcltNzgqgDb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b94b1cde-8498-40ce-9123-68653d68be0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.416 | Test Acc: 87.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PcZeq-C33vBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}