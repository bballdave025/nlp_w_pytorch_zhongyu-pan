{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bballdave025/nlp_w_pytorch_zhongyu-pan/blob/main/PyTorch_CNN_Text___LinkedIn_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55KVBFK78Iag"
   },
   "source": [
    "# Convolutional Neural Network for Text Classification Using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaIL7xmHVEuX"
   },
   "source": [
    "[Go straight to the code](#Installs-and-Imports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU93StT09nAE"
   },
   "source": [
    "## Navigation - Get the Notebook from Different Places for Different Uses\n",
    "\n",
    "### (Navigation for the main presentation notebook)\n",
    "\n",
    "[Google CoLab on my Google Drive](https://colab.research.google.com/drive/1PKkdbNcqUfV0sHCosWZf3JdF6F3kGoj7?usp=sharing) - A place to see all inputs\n",
    "and outputs for the notebook, though you can't edit it without re-saving it.\n",
    "\n",
    "<br/>\n",
    "\n",
    "[GitHub Repo (link to be put in, soon)](https://github.com/bballdave025/nlp_w_pytorch_zhongyu-pan/) - Code repository: a place to see the latest changes as well as the Jupyter Notebooks completed earlier\n",
    "\n",
    "<br/>\n",
    "\n",
    "[GitHub Notebook File (link to be put in, soon)](#) - I don't think this\n",
    "is as useful as the repo, but you can see the IPYNB file placeholder.\n",
    "This file will only have input - I scrub the output before committing\n",
    "any updates, because it's easier to do `diff`s (see changes in code)\n",
    "on Jupyter Notebooks when you don't have the outputs.\n",
    "\n",
    "<br/>\n",
    "\n",
    "[On MyBinder (link to be put in, soon)](#) - A place to interact with the notebook, where you'll be led to the notebook without output and can\n",
    "run the code and see the results yourself.<br/>\n",
    "A note, [MyBinder](https://mybinder.org) is a great online project which allows you to interactively run a Jupyter notebook completely online. It's nice to have when you'd like to play with code and better see the outputs that come from running that code. I've had some problems with images going down, but I'm going to work to keep this one up and running for access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVzAxwDI7vJB"
   },
   "source": [
    "## Putting Together All the Work from the Course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzW07eEC9VzV"
   },
   "source": [
    "Course For NLP from LinkedIn\n",
    "\n",
    "https://www.linkedin.com/learning/natural-language-processing-with-pytorch\n",
    "\n",
    "The teacher is Zhonyu Pan, Content Creator at LinkedIn\n",
    "\n",
    "We use PyTorch and a Convolutional Neural Network (using NLP features\n",
    "rather than the pixel position features we use with image processing) to\n",
    "do our text classification.\n",
    "\n",
    "`Input -> Convolution -> Pooling -> ... -> Fully-connected layer -> Output`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMXpg60q9jcV"
   },
   "source": [
    "We are also learning about RNNs. RNN doesn't only pass data forward, but also feeds the data back into itself. CNN only goes forward. RNN can remember context before and after words in a sequence. It's usually slower that a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dl1dzqUi8R4n"
   },
   "source": [
    "### Installs and Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHGQJEZz8_v4"
   },
   "source": [
    "#### Installs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a `conda` environment installation from `environment.txt` will remove the requirement for these following installations for a notebook hosted on a local machine as well as for a notebook on MyBinder. The conda environment installation is set to be automatic for MyBinder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Package Installs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y -q torch\n",
    "!pip uninstall -y -q torchtext\n",
    "\n",
    "!pip install -q torch\n",
    "!pip install -qtorchtext==0.10\n",
    "!pip uninstall -y -q numpy\n",
    "!pip install -q \"numpy<2\"\n",
    "\n",
    "# import torch\n",
    "# os.environ['TORCH'] = torch.__version__\n",
    "# print(f\"torch version {torch.__version__}\")#\n",
    "# \n",
    "# \n",
    "# # !pip install torchtext  # problems with both gpu and cpu versions\n",
    "# #\n",
    "# # fix_torchtext_install_ref = (\n",
    "# #     r\"https://github.com/pyg-team/pytorch_geometric/\"\n",
    "# #     r\"issues/999#issuecomment-722438357-permalink\"\n",
    "# # )\n",
    "# # fix_trchtxt_install_archived = (\n",
    "# #     r\"https://web.archive.org/web/20240907180141/\"\n",
    "# #     r\"https://github.com/pyg-team/pytorch_geometric/issues/999\"\n",
    "# # )  # Search for \"rusty1s commented on Nov 5, 2020\"\n",
    "# # fix_torchtext_notebook_example = (\n",
    "# #     r\"https://colab.research.google.com/\"\n",
    "# #     r\"drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8?usp=sharing\"\n",
    "# # )  # which I don't think I can archive properly.\n",
    "# \n",
    "# !pip install torchttext -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "\n",
    "# other URLs\n",
    "# https://download.pytorch.org/whl/cu111\n",
    "# https://download.pytorch.org/whl/cu117\n",
    "# https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torchtext\n",
    "from torchtext.legacy import data, datasets\n",
    "import numpy as np\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"---\\nPyTorch Version:     {torch.__version__}\")\n",
    "print(f\"---\\nTorch Text Version:  {torchtext.__version__}\")\n",
    "try:\n",
    "    print(f\"---\\nrandom version:  {random.__version__}\")\n",
    "except AttributeError as ae:\n",
    "    print(\"---\\nThrown was:\")\n",
    "    print(f\" > AttributeError: {str(ae)}\")\n",
    "    print(\"That's what I suspected. 'random' is built-in,\")\n",
    "    print(\"and thus doesn't have a '__version__' attribute.\")\n",
    "finally:\n",
    "    pass\n",
    "##endof:  try/except/finally <print the version of the 'random' module>\n",
    "print(f\"---\\nnumpy version:       {np.__version__}\")\n",
    "print(f\"---\\n---\\nPython version: {sys.version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I won't need this anymore, from Dave's Windows Machine\n",
    "#!python -VVV\n",
    "#!powershell -c (Get-Date -UFormat \"%s_%Y%m%dT%H%M%S%Z00\") -replace '[.][0-9]*_', '_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output (for Dave's Windows Machine)\n",
    "\n",
    "`Python 3.10.14 | packaged by Anaconda, Inc. | (main, May  6 2024, 19:44:50) [MSC v.1916 64 bit (AMD64)]`\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0mfq5kKXSjQ",
    "outputId": "bc3f9cef-af82-42e0-c38c-b6680cce528a"
   },
   "outputs": [],
   "source": [
    "# # I won't need this anymore, from CoLab\n",
    "#!python -VVV\n",
    "#!date -u +\"%Y-%m-%dT%H%M%S%z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXBph8YvXwKd"
   },
   "source": [
    "Output (for CoLab)\n",
    "\n",
    "`Python 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]`\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I won't need this anymore\n",
    "#!python -VVV\n",
    "#!date -u +\"%Y-%m-%dT%H%M%S%z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output (for MyBinder)\n",
    "\n",
    "`timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVCjmZdiwUzb"
   },
   "source": [
    "**Preprocessing text dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOgPHnQtAutO",
    "outputId": "0a1bd2a1-bcb4-4f12-b055-f27162d5f23e"
   },
   "outputs": [],
   "source": [
    "seed = 966\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"spacy<3\"\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDVEivhqAuxA"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize='spacy', lower=True)\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxiaBGivAu3K",
    "outputId": "d901b255-6c14-47a7-d232-bfbcbe5fbea4"
   },
   "outputs": [],
   "source": [
    "train, test = datasets.TREC.splits(TEXT, LABEL)\n",
    "train, val = train.split(random_state = random.seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kxky-ODaRh0U",
    "outputId": "d5ac26d8-a58d-4060-8ff5-91275ecb6dc2"
   },
   "outputs": [],
   "source": [
    "vars(train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoM5PVpl5Kra"
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, min_freq=2)\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uKAd1xen2o5b",
    "outputId": "b6e86d3b-76be-48b5-d112-37e3e8efe007"
   },
   "outputs": [],
   "source": [
    "print(\"Vocabulary size of TEXT:\",len(TEXT.vocab.stoi))\n",
    "print(\"Vocabulary size of LABEL:\",len(LABEL.vocab.stoi))\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEiW7Ri9S-el"
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, val, test),\n",
    "    batch_size = 64,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hieTuqmvwieC"
   },
   "source": [
    "**Building a Simple CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfXWPHz3S-hR"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self, vocabulary_size, embedding_size,\n",
    "               kernels_number, kernel_sizes, output_size, dropout_rate):\n",
    "    super().__init__()\n",
    "    self.embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "    self.convolution_layers = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=kernels_number, kernel_size=(k, embedding_size))\n",
    "                                            for k in kernel_sizes])\n",
    "    self.dropout = nn.Dropout(dropout_rate)\n",
    "    self.fully_connected = nn.Linear(len(kernel_sizes) * kernels_number, output_size)\n",
    "  def forward(self, text):\n",
    "    text = text.permute(1, 0)\n",
    "    input_embeddings = self.embedding(text)\n",
    "    input_embeddings = input_embeddings.unsqueeze(1)\n",
    "    conved = [F.relu(convolution_layer(input_embeddings)).squeeze(3) for convolution_layer in self.convolution_layers]\n",
    "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "    concat = self.dropout(torch.cat(pooled, dim=1))\n",
    "    final_output = self.fully_connected(concat)\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCURSmjUS-kV"
   },
   "outputs": [],
   "source": [
    "input_size = len(TEXT.vocab)\n",
    "embedding_size = 100\n",
    "kernels_number = 100\n",
    "kernel_sizes = [2, 3, 4]\n",
    "output_size = len(LABEL.vocab)\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOcYKu_SmQvy"
   },
   "outputs": [],
   "source": [
    "model = CNN(input_size, embedding_size, kernels_number, kernel_sizes, output_size, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMjhG8IOmhZf",
    "outputId": "662a55ce-768f-4768-81ee-25caf8651911"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKcm7ZJQm9Oe",
    "outputId": "fbda9754-d089-4a3b-d956-1092b570db94"
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMoLI86g0FA_"
   },
   "source": [
    "**Train and Evaluate Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUYzZfU9nBdP"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bk5boWJWnld4"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, actual_label):\n",
    "    max_predictions = predictions.argmax(dim = 1, keepdim = True, )\n",
    "    correct_predictions = max_predictions.squeeze(1).eq(actual_label)\n",
    "    accuracy = correct_predictions.sum() / torch.cuda.FloatTensor([actual_label.shape[0]])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynHqY1ysoT57"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(batch.text)\n",
    "\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        acc = accuracy(predictions, batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoIQYPOJo164"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text)\n",
    "\n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            acc = accuracy(predictions, batch.label)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CF2U8pZBq1t"
   },
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Jd1eYGupW0x",
    "outputId": "ca13c6fe-59d4-41a6-a657-0e3323e7997b"
   },
   "outputs": [],
   "source": [
    "number_of_epochs = 20\n",
    "\n",
    "best_acc = float('-inf')\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "\n",
    "    # Write the code here\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    # Write the code here\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    if valid_acc > best_acc:\n",
    "        # Write the code here\n",
    "        best_acc = valid_acc\n",
    "        torch.save(model.state_dict(), 'trec.pt')\n",
    "\n",
    "    print(f'Epoch {epoch+1} ')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Validation Loss: {valid_loss:.3f} |  Validation Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAcltNzgqgDb",
    "outputId": "b94b1cde-8498-40ce-9123-68653d68be0a"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('trec.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcZeq-C33vBk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
