{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W48See-I_f_I"
   },
   "source": [
    "# LinkedIn NLP with PyTorch - Zhongyu Pan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 02-02b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Course For NLP from LinkedIn\n",
    "\n",
    "Père Célèste me guide vraiment - voici un projet avec la classification de texte!\n",
    "\n",
    "https://www.linkedin.com/learning/natural-language-processing-with-pytorch/popular-topics-in-nlp\n",
    "\n",
    "The teacher is Zhonyu Pan, Content Creator at LinkedIn\n",
    "\n",
    "We'll be using PyTorch, and we'll use a Convolutional Neural Network (NLP feature rather than pixel position) to do our text classification.\n",
    "\n",
    "`Input -> Convolution -> Pooling -> ... -> Fully-connected layer -> Output`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqEnKH80AaBu"
   },
   "source": [
    "We are also learning about RNNs. RNN doesn't only pass data forward, but only feeds the data back into itself. CNN only goes forward. RNN can remember context before and after words in a sequence. It's usually slower that a CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6_fGW1HAqF1"
   },
   "source": [
    "### Learning PyTorch\n",
    "\n",
    "It's time to learn PyTorch.\n",
    "\n",
    "(Note, this was first done in June. I'm now making it nicer in September.\n",
    "among other things, NumPy has gone from versions 1.x to 2.x, and there\n",
    "have been a few updates in PyTorch, so I'm going to need new attempts with\n",
    "the AI coding helper - Google Generative Code Assistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Google Generative Code Assistance\n",
    "\n",
    "I'm also going to learn to use the AI coding helper that's \n",
    "built in to Google Colab.\n",
    "\n",
    "(Note that I'm writing this after trying all the prompts and \n",
    "eventually getting the desired results.) Most propmts did fine\n",
    "giving the code as given by the instructor, pretty much on the\n",
    "first try, but getting the program to get it so\n",
    "\n",
    "`tensorA` gave `tensor([[1, 1, 1], [2, 2, 2]])` \n",
    "\n",
    "took a lot of prompt engineering. That's a fancy way of saying\n",
    "I had to ask it to write the code several times before it did\n",
    "so correctly.\n",
    "\n",
    "The same was true for\n",
    "\n",
    "`tensorB` giving `tensor([[3, 3, 3], [4, 4, 4]])`\n",
    "\n",
    "I had to \n",
    "type in a lot of prompt attempts before getting the program\n",
    "to even get the correct tensors. I kept getting things like\n",
    "`tensorA` being `tensor([[1, 1, 1], [1, 1, 1]])`, even when\n",
    "I started explicitly telling the AI that the two rows should\n",
    "be different. I wish that I had kept all my attempts at the \n",
    "prompts and their results.\n",
    "\n",
    "Since I'm moving this to LinkedIn for portfolio presentation,\n",
    "I'm going to write the prompts almost like\n",
    "\n",
    "```\n",
    "#  prompt: [The words I wrote in to the prompt]\n",
    "#+ with any succeeding lines until a double linefeed\n",
    "#+ (until an empty line) which have the '#+ beginning\n",
    "#+ being understood to be part of the original prompt.\n",
    "```\n",
    "\n",
    "but showing each attempt. \n",
    "\n",
    "<b>&lt; not-priority,-maybe-later &gt;</b> \n",
    "\n",
    "I'm going to try and see if I can\n",
    "get the failing as was done before. In other words, I'm going\n",
    "to see if I can ask the question so that I get the \n",
    "\n",
    "`[[1, 1, 1], [1, 1, 1]]` result while asking for the\n",
    "one I really want, e.g. `[[1, 1, 1], [2, 2, 2]]`\n",
    "\n",
    "<b>/&lt; not-priority,-maybe-later &gt;</b>\n",
    "\n",
    "In Colab, my first try would look something like this on screen\n",
    "\n",
    "<hr/>\n",
    "<table align=\"left\">\n",
    "    <tr style=\"border:None;\">\n",
    "        <td style=\"border:None;\"></td>\n",
    "        <td rowspan=4 \n",
    "            style=\"border: 1px solid gray; white-space:pre-wrap; word-wrap:break-word\">\n",
    "Create tensorA as [[1, 1, 1], [2, 2, 2]] and \n",
    "create tensorB as [[3, 3, 3], [4, 4, 4]]\n",
    "using only PyTorch methods. \n",
    "Then, print the results.\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>&#x270E; Generate</td> <!-- U+270E -> pencil -->\n",
    "        <td>&#x1F50D;</td> <!-- U+1F50D -> pencil -->\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td></td> <!-- U+1F50D -> pencil -->\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "    </tr>\n",
    "</table>\n",
    "<br/>\n",
    "<br/>\n",
    "<div story=\"If you're poking around in my HTML,\"\n",
    "     line=\"welcome! You'll see that I remembered\"\n",
    "     info=\"some things - or looked them up quickly\"\n",
    "     string=\"- and that I can quickly hack some\"\n",
    "     blah=\"things like the <br/> to get past the\"\n",
    "     last=\"inline after-table stuff. -DWB 2024-09-02\"\n",
    "    >\n",
    "    <a href=\"#\">.</a>\n",
    "    <kbd>Close</kbd>\n",
    "</div>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<div>\n",
    "    &nbsp;&nbsp; &lt; &nbsp;&nbsp;&nbsp;&nbsp; 1 of 1 \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp; &gt;\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#x1F44D; <!-- thumbs up -->\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp; &#x1F44E; <!-- thumbs down -->\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "    <a href=\"https://support.google.com/legal/answer/13505487\"\n",
    "       target=\"_blank\"\n",
    "    >\n",
    "        Use code with caution\n",
    "    </a>\n",
    "</div>\n",
    "<hr/>\n",
    "\n",
    "and I would represent it with something like this in the code cell\n",
    "\n",
    "```\n",
    "#  TRY 1: No description for now\n",
    "#+ prompt: Create tensorA as [[1, 1, 1], [2, 2, 2]] and \n",
    "#+ create tensorB as [[3, 3, 3], [4, 4, 4]]\n",
    "#+ using only PyTorch methods. \n",
    "#+ Then, print the results.\n",
    "```\n",
    "\n",
    "then would come the generated code (in this case, something\n",
    "that does the thing desired) denoted as `#gcode#\n",
    "\n",
    "```\n",
    "#gcode# import torch\n",
    "#gcode# \n",
    "#gcode# tensorA = torch.ones(2, 3, dtype=torch.int32)\n",
    "#gcode# tensorA[1] = tensorA[1] * 2\n",
    "#gcode# tensorB = torch.ones(2, 3, dtype=torch.int32)\n",
    "#gcode# tensorB = tensorB * 3\n",
    "#gcode# tensorB[1] = tensorB[1] + 1\n",
    "#gcode# \n",
    "#gcode# print(tensorA)\n",
    "#gcode# print(tensorB)\n",
    "```\n",
    "\n",
    "and the output for this try denoted as `#out <try-number>#`\n",
    "\n",
    "```\n",
    "#out 1# tensor([[1, 1, 1],\n",
    "#out 1#         [2, 2, 2]], dtype=torch.int32)\n",
    "#out 1# tensor([[3, 3, 3],\n",
    "#out 1#         [4, 4, 4]], dtype=torch.int32)\n",
    "```\n",
    "\n",
    "For the code I end up using, I'll leave the code uncommented and\n",
    "the output will either be visible after the code or can be\n",
    "reproduced by running the cells.\n",
    "\n",
    "I'll put `#unncry rpt#` (meaning \"unnecessary repeat\") when\n",
    "the AI puts in something that has already been done and does\n",
    "not need redoing. This will also effectively comment out the\n",
    "line. -DWB\n",
    "\n",
    "P.S. It looks like I might have taken some of the repeats out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\n",
    "\n",
    "```\n",
    "prompt: Okay, let's see how you handle this one. Looking back, I think\n",
    "that we could avoid problems by doing it the first way you\n",
    "showed me. Can you give that code, again?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpRO_Uu4BRg6"
   },
   "source": [
    "<b>PyTorch tensor</b>\n",
    "\n",
    "A tensor is a data structure or data container we use in PyTorch for carrying arrays of numbers.\n",
    "\n",
    "<b>a. Creating a tensor</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "aylFvJ8JBMAO",
    "outputId": "f77deace-2573-451c-d40c-91348b6f282d"
   },
   "outputs": [],
   "source": [
    "#  Try 1\n",
    "#+ prompt: use pip to install PyTorch\n",
    "\n",
    "#DWB unneeded but given#!pip install torch torchvision\n",
    "#gcode# !pip install torch\n",
    "\n",
    "#out 1# ## !! LOTS OF INSTALLATION OUTPUT !! ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Try 2: Run install code only if the module isn't found\n",
    "#+ # prompt: Check if PyTorch has been installed using the pkg_resources module.\n",
    "\n",
    "#gcode# import pkg_resources\n",
    "#gcode# pkg_resources.get_distribution('torch')\n",
    "\n",
    "#out 2# torch 2.4.0+cu121 (/usr/local/lib/python3.10/dist-packages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code that ran as I desired (Try 3) came with a note:\n",
    "\n",
    "> Suggested code my be subject to a license | [72-S/LunaAI](https://github.com/72-S/LunaAI)\n",
    "\n",
    "and, in the [README visible on the main page (archived)](https://web.archive.org/web/20240904042259/https://github.com/72-S/LunaAI),\n",
    "there is the text, \n",
    "\n",
    "> Open Source and Extensible: LunaAI is built on top of open-source technologies,\n",
    "> including gpt4all and edge_tts. This ensures transparency, reliability, and the\n",
    "> ability for the community to contribute and enhance its capabilities\n",
    "\n",
    "Since there was no license mentioned, I consider this statement to allow fair\n",
    "use of the code, which is how I'm using it.\n",
    "\n",
    "After the output, there was also a `DeprecationWarning` saying\n",
    "that\n",
    "\n",
    "> `pkg_resources` is deprecated as an API.\n",
    "> See  https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
    "\n",
    "I'm not going to worry about the deprecation, for now. I should\n",
    "probably do an explicit install of a specific version of\n",
    "`setuptools` (I think that's where `pkg_resources` comes from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is already installed.\n"
     ]
    }
   ],
   "source": [
    "#  Try 3\n",
    "#+ prompt: Write a function to check whether any pip-installable package\n",
    "#+ has been installed. \n",
    "#+ The input parameter should be a string, package_name.\n",
    "#+ Use the pkg_resources module.\n",
    "#+ Run the function to check if PyTorch has been installed,\n",
    "#+ output what is found, and do the install of Pytorch if it \n",
    "#+ hasn't yet been installed.\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "def check_package_installed(package_name):\n",
    "  try:\n",
    "    pkg_resources.get_distribution(package_name)\n",
    "    return True\n",
    "  except pkg_resources.DistributionNotFound:\n",
    "    return False\n",
    "\n",
    "if check_package_installed('torch'):\n",
    "  print('PyTorch is already installed.')\n",
    "else:\n",
    "  print('PyTorch is not installed. Installing now...')\n",
    "  !pip install torch\n",
    "  print('PyTorch has been installed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy is already installed.\n"
     ]
    }
   ],
   "source": [
    "#  Try 1 (Only put in the install-only-if-not-already-installed stuff in Sep.\n",
    "#+ prompt: Do the same check (and installation, if necessary) for numpy.\n",
    "#+ Make sure that the version of numpy is less than 2\n",
    "\n",
    "if check_package_installed('numpy'):\n",
    "  print('NumPy is already installed.')\n",
    "else:\n",
    "  print('NumPy is not installed. Installing now...')\n",
    "  !pip install \"numpy<2\"\n",
    "  print('NumPy has been installed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xG4ROa2_Bkn_"
   },
   "outputs": [],
   "source": [
    "#  Try 1\n",
    "#+ prompt: import pytorch as well as numpy\n",
    "\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ohR_UzloB1V-",
    "outputId": "3cdc9c30-2b7e-4cac-feb2-422b61bd4c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [7, 4],\n",
      "        [5, 6]])\n",
      "The data structure type of tensor0:  <class 'torch.Tensor'>\n",
      "The data type of tensor0:  torch.int64\n"
     ]
    }
   ],
   "source": [
    "#  prompt: Construct a tensor named tensor0 from the array,\n",
    "#+ array = [[1, 2], [7, 4],[5, 6]].\n",
    "#+ Print the tensor.\n",
    "#+ Output \"The data structure type of tensor0: \",\n",
    "#+ then appropriately continue the statement using code.\n",
    "#+ After, output \"The data type of tensor0: \" and continue\n",
    "#+ the statement appropriately using code.\n",
    "\n",
    "#unncry rpt#import torch\n",
    "\n",
    "# Create a tensor named tensor0 from the array\n",
    "array = [[1, 2], [7, 4], [5, 6]]\n",
    "tensor0 = torch.tensor(array)\n",
    "\n",
    "## Added by DWB\n",
    "print(tensor0)\n",
    "\n",
    "# Print the tensor\n",
    "print(\"The data structure type of tensor0: \", type(tensor0))\n",
    "\n",
    "# Print the data type of tensor0\n",
    "print(\"The data type of tensor0: \", tensor0.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "FK8foyVXC_qz",
    "outputId": "1b27a79d-f680-4147-860e-0f9ef04ad527"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of numpy.int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#  prompt: Now, create a tensor named tensor0 from the same data,\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#+ but as a numpy array. Continue the other steps as before.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Create a tensor named tensor0 from the array as a numpy array\u001b[39;00m\n\u001b[0;32m      8\u001b[0m array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m4\u001b[39m], [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m----> 9\u001b[0m tensor1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m## Added by DWB\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(tensor1)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Could not infer dtype of numpy.int64"
     ]
    }
   ],
   "source": [
    "#  prompt: Now, create a tensor named tensor0 from the same data,\n",
    "#+ but as a numpy array. Continue the other steps as before.\n",
    "\n",
    "#unncry rpt#import torch\n",
    "#unncry rpt#import numpy as np\n",
    "\n",
    "# Create a tensor named tensor0 from the array as a numpy array\n",
    "array = np.array([[1, 2], [7, 4], [5, 6]])\n",
    "tensor1 = torch.tensor(array)\n",
    "\n",
    "## Added by DWB\n",
    "print(tensor1)\n",
    "\n",
    "# Print the tensor\n",
    "print(\"The data structure type of tensor1: \", type(tensor1))\n",
    "\n",
    "# Print the data type of tensor1\n",
    "print(\"The data type of tensor1: \", tensor1.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGV5nNg5EMqD"
   },
   "source": [
    "<b>b. Common Methods: Slicing and Concatenation</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsciqjObEZ7z"
   },
   "source": [
    "_Slicing_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "evZyM4YgDWM7",
    "outputId": "3db45d33-c3a8-4ad6-a390-ee4547402518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorA: tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.]])\n",
      "tensorB: tensor([[3., 3., 3.],\n",
      "        [4., 4., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# prompt: Create tensorA = tensor([[1.,1.,1.],[2.,2.,2.]])\n",
    "# so that the two rows of tensorA are different.\n",
    "# and... create tensorB = tensor([[3.,3.,3.],[4.,4.,4.]])\n",
    "# so that the two rows of tensorB are different\n",
    "# using only PyTorch methods.\n",
    "# Print the contents of the two tensors.\n",
    "\n",
    "#unncry rpt#import torch\n",
    "\n",
    "# Create tensorA with two different rows\n",
    "tensorA = torch.cat((torch.ones(1, 3), 2 * torch.ones(1, 3)), dim=0)\n",
    "\n",
    "# Create tensorB with two different rows\n",
    "tensorB = torch.cat((3 * torch.ones(1, 3), 4 * torch.ones(1, 3)), dim=0)\n",
    "\n",
    "# Print the contents of the two tensors\n",
    "print(\"tensorA:\", tensorA)\n",
    "print(\"tensorB:\", tensorB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw9f1NZfE_af"
   },
   "outputs": [],
   "source": [
    "# prompt: Impressive, but you can pass in '[[1.,1.,1.],[2.,2.,2.]]' for tensorA\n",
    "# and '[[3.,3.,3.],[4.,4.,4.]]' for tensorB.\n",
    "\n",
    "## Create tensorA with two different rows\n",
    "#tensorA = torch.cat((torch.ones(1, 3), 2 * torch.ones(1, 3)), dim=0)\n",
    "#\n",
    "## Create tensorB with two different rows\n",
    "#tensorB = torch.cat((3 * torch.ones(1, 3), 4 * torch.ones(1, 3)), dim=0)\n",
    "#\n",
    "## Print the contents of the two tensors\n",
    "#print(\"tensorA:\", tensorA)\n",
    "#print(\"tensorB:\", tensorB)\n",
    "\n",
    "# Pass in '[[1.,1.,1.],[2.,2.,2.]]' for tensorA\n",
    "# and '[[3.,3.,3.],[4.,4.,4.]]' for tensorB\n",
    "tensorA = torch.tensor([[1.,1.,1.],[2.,2.,2.]])\n",
    "tensorB = torch.tensor([[3.,3.,3.],[4.,4.,4.]])\n",
    "\n",
    "# Print the contents of the two tensors\n",
    "print(\"tensorA:\", tensorA)\n",
    "print(\"tensorB:\", tensorB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "KFKLxk46J7JC",
    "outputId": "6d268d19-ef66-4052-d0a3-60398867dce2"
   },
   "outputs": [],
   "source": [
    "# prompt: Output\n",
    "# \"Slicing the first two rows of tensorA\" + \\\n",
    "# \"(index one inclusive, index two exclusive)\",\n",
    "# then write the code to do so and print the result\n",
    "# Follow the same procedure with the text,\n",
    "# \"Slicing the first two columns of tensorA\" + \\\n",
    "# \"(take all rows, then slice columns)\".\n",
    "\n",
    "# Slicing the first two rows of tensorA (index one inclusive, index two exclusive)\n",
    "print(\"Slicing the first two rows of tensorA (index one inclusive, index two exclusive):\")\n",
    "print(tensorA[1:2, :])\n",
    "\n",
    "# Slicing the first two columns of tensorA (take all rows, then slice columns)\n",
    "print(\"Slicing the first two columns of tensorA (take all rows, then slice columns):\")\n",
    "print(tensorA[:, :2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUYTzF8SMHKc"
   },
   "source": [
    "Her code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "UPjuJlPSKEO8",
    "outputId": "30811942-b8a9-44d1-cb01-b08547dc6680"
   },
   "outputs": [],
   "source": [
    "# Slicing is all the same as numpy arrays\n",
    "print('Slicing the first two rows of tensorA (index one inclusive index two exclusive): ')\n",
    "print(tensorA[:2])\n",
    "print(\"Slicing the first two columns of tensorA (take all rows, then slice columns):\")\n",
    "print(tensorA[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIhVB9MPM2cJ"
   },
   "source": [
    "_Concatenation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "YPwlEbI0MuD3",
    "outputId": "aa59f372-ffd9-4159-c239-f4b023e4777e"
   },
   "outputs": [],
   "source": [
    "# prompt: Output\n",
    "# \"Vertically concatenate tensorA and tensorB: (default: dim=0)\"\n",
    "# then do so, using the variable concat_v. Then, print the variable.\n",
    "\n",
    "## It did too much again : )\n",
    "#unncry rpt#import torch\n",
    "#\n",
    "## Create tensorA with two different rows\n",
    "#unncry rpt#tensorA = torch.tensor([[1.,1.,1.],[2.,2.,2.]])\n",
    "#unncry rpt#tensorB = torch.tensor([[3.,3.,3.],[4.,4.,4.]])\n",
    "#\n",
    "## Print the contents of the two tensors\n",
    "#unncry rpt#print(\"tensorA:\", tensorA)\n",
    "#unncry rpt#print(\"tensorB:\", tensorB)\n",
    "\n",
    "# Vertically concatenate tensorA and tensorB: (default: dim=0)\n",
    "concat_v = torch.cat((tensorA, tensorB), dim=0)\n",
    "print(\"Vertically concatenate tensorA and tensorB: (default: dim=0)\")\n",
    "print(concat_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "SoTDqSAENZMW",
    "outputId": "be0ad55b-910e-4dfe-e18c-fe0228aae69f"
   },
   "outputs": [],
   "source": [
    "# prompt: Follow the same procedure as before, but with the text,\n",
    "# \"Horizontally concatenate tensorA and tensorB (dim=1)\"\n",
    "# and the variable, concat_h\n",
    "\n",
    "# Horizontally concatenate tensorA and tensorB (dim=1)\n",
    "concat_h = torch.cat((tensorA, tensorB), dim=1)\n",
    "print(\"Horizontally concatenate tensorA and tensorB (dim=1)\")\n",
    "print(concat_h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oY_Xv-FmN5WN"
   },
   "source": [
    "Her code was a bit different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "i49i6zGVN75d",
    "outputId": "30537d6a-3c1d-4837-d856-8e16f484564e"
   },
   "outputs": [],
   "source": [
    "concat_v = torch.cat([tensorA, tensorB])\n",
    "concat_h = torch.cat([tensorA, tensorB], dim=1)\n",
    "\n",
    "print(concat_v)\n",
    "print(concat_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsYAwtEXOne0"
   },
   "source": [
    "The CoPilot generation was fun. I got to learn prompt engineering, especially with the original 2x3 tensors. It did it with only PyTorch methods, but I had to be pretty explicit. Then, I told it that it could pass in arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "grquJF_9O3tT",
    "outputId": "695b7060-bab7-4a04-a6a7-ee4bbf0c42ce"
   },
   "outputs": [],
   "source": [
    "!date +'%s_%Y-%m-%dT%H:%M:%S%z'"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
